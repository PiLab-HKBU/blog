import{_ as o,W as a,X as i,Y as r,Z as e,$ as t,a0 as s,C as l}from"./framework-43e8ff1c.js";const h={},p={href:"https://lileipisces.github.io/",target:"_blank",rel:"noopener noreferrer"},c=r("p",null,[r("em",null,"Department of Computer Science, Hong Kong Baptist University")],-1),_={href:"https://github.com/lileipisces/NLG4RS",target:"_blank",rel:"noopener noreferrer"},d=r("h2",{id:"创建动机",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#创建动机","aria-hidden":"true"},"#"),e(" 创建动机")],-1),f={href:"https://github.com/pytorch/examples/issues/846",target:"_blank",rel:"noopener noreferrer"},g=s('<p>有人可能会问：为什么不开发一套框架或者库？一则，本人时间精力水平都有限。二则，为了考虑通用性，框架或库的设计通常一个类嵌套着另一个类，如此往复（如huggingface的transformers库），增加了代码的阅读障碍。因此，本人不打算做成框架/库，甚至不会将这些模型放到同一个项目里。与此相反，只是在这里做一个总的介绍，大家可以访问感兴趣的模型项目链接，按照自己的需求灵活地添加各种功能。</p><h2 id="问题定义" tabindex="-1"><a class="header-anchor" href="#问题定义" aria-hidden="true">#</a> 问题定义</h2><p>给定一个用户ID和一个物品ID，让模型生成一段文本（如图1）。在推荐解释生成的场景下，就是让模型解释为什么某个产品要推荐给某个用户。额外的数据（如知识图谱）这里暂不考虑，留给大家探索。</p><p><img src="https://picx.zhimg.com/80/v2-2d3b28cf896874a5c7858777ead4042a_1440w.png?source=d16d100b" alt="img" loading="lazy"> Figure 1: 基于推荐系统的自然语言生成.</p><h2 id="公开数据集及创建方法" tabindex="-1"><a class="header-anchor" href="#公开数据集及创建方法" aria-hidden="true">#</a> 公开数据集及创建方法</h2>',5),u=r("strong",null,"寿司",-1),m=r("strong",null,"好吃",-1),b={href:"https://github.com/evison/Sentires",target:"_blank",rel:"noopener noreferrer"},k=r("p",null,"好用归好用，美中不足的是阅读文档来了解这个工具的学习成本并不低，普通人（譬如本人）没个几天时间压根拿不下来。另外，这个工具是用Java写的，但现在很多人更熟悉Python，如何把它们连接起来也是个问题。本人给这个工具套了一层Python的壳，由于一开始的目的是为了得到可以用作推荐解释的句子，丰富了功能，可以从评论中抽出（feature，opinion，sentiment，sentence）四元组。有了这个壳，研究人员可以不用花功夫去研究这个工具的文档，只需要改Python代码。送佛送到西，改哪一行本人都写好了。我们用这个工具总共创建了三个公开数据集（TripAdvisor Hong Kong、Amazon Movies & TV以及Yelp 2019）。原文及数据和代码链接如下：",-1),L={href:"https://lileipisces.github.io/",target:"_blank",rel:"noopener noreferrer"},P={href:"http://yongfeng.me/",target:"_blank",rel:"noopener noreferrer"},T={href:"https://www.comp.hkbu.edu.hk/~lichen/",target:"_blank",rel:"noopener noreferrer"},R={href:"https://doi.org/10.1145/3340531.3411992",target:"_blank",rel:"noopener noreferrer"},I={href:"https://github.com/lileipisces/Sentires-Guide",target:"_blank",rel:"noopener noreferrer"},y={href:"https://lifehkbueduhk-my.sharepoint.com/:f:/g/personal/16484134_life_hkbu_edu_hk/Eln600lqZdVBslRwNcAJL5cBarq6Mt8WzDKpkq1YCqQjfQ?e=cISb1C",target:"_blank",rel:"noopener noreferrer"},x={href:"http://yongfeng.me/",target:"_blank",rel:"noopener noreferrer"},w={href:"https://dl.acm.org/doi/10.1145/2600428.2609501",target:"_blank",rel:"noopener noreferrer"},C={href:"https://github.com/evison/Sentires",target:"_blank",rel:"noopener noreferrer"},D=r("h2",{id:"评估指标",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#评估指标","aria-hidden":"true"},"#"),e(" 评估指标")],-1),E=r("p",null,"现有工作通常将机器翻译里的BLEU还有文本摘要里的ROUGE视作解释性的评价指标，我们认为这样是不全面的，因为它们更加侧重的是句子的可读性（通过跟参照文本进行对比），而不是解释性。比如，有的模型有时候会对不同的样本生成一模一样的句子，显然这样是不合理的，但是BLEU和ROUGE却没法反映出来。另外，对话系统中也常常会出现套话（universal reply）的情况，如“我不知道”和“好的”。为了定量评估这个问题，我们设计了一个评测句子多样性的指标USR。除此之外，我们还针对推荐系统的解释性提出了三个指标，用以评价句子里包含的产品属性（item feature）的匹配率FMR、覆盖率FCR和多样性DIV。这四个指标出自下面这个工作。它们并不完美，但代表我们对这个研究方向的一些思考。后面将要介绍的模型的实现中均配备这里提到的六大指标。",-1),S={href:"https://lileipisces.github.io/",target:"_blank",rel:"noopener noreferrer"},v={href:"http://yongfeng.me/",target:"_blank",rel:"noopener noreferrer"},G={href:"https://www.comp.hkbu.edu.hk/~lichen/",target:"_blank",rel:"noopener noreferrer"},N={href:"https://doi.org/10.1145/3340531.3411992",target:"_blank",rel:"noopener noreferrer"},M=r("h2",{id:"模型的pytorch实现",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#模型的pytorch实现","aria-hidden":"true"},"#"),e(" 模型的PyTorch实现")],-1),A=r("p",null,"以下简要介绍四个典型的基于推荐系统的自然语言生成模型，包括GPT-2、Transformer、GRU和LSTM。前两个是本人自己的工作，后两个是两位NLP大佬的工作（斗胆并列在一起）。模型全部用PyTorch 1.6实现/复现，代码风格相似，“举一反三”。",-1),U=r("h3",{id:"pepler-gpt-2",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#pepler-gpt-2","aria-hidden":"true"},"#"),e(" PEPLER (GPT-2)")],-1),B=r("p",null,"这是本人近期的工作成果，已被ACM TOIS接收。在这个工作中，我们将ID作为提示（prompt）输入到预训练模型中，用以生成推荐解释。主要的难点是ID跟文本并不在同一个语义空间，同时大改预训练模型的结构也不太可能。受当前火热的提示学习（prompt learning）的启发，我们设计了两种方案：把ID替换成文本（离散提示学习），以及直接输入ID向量（连续提示学习）。对于后者，ID向量是随机初始化的，跟预训练过的模型处于不同的学习阶段，如何弥补它们之间的差距又是一个问题。为此我们进一步提出两种训练策略：把ID向量先训练一遍再跟预训练模型一起训练，以及将推荐任务作为解释任务的辅助正则项。此外没有添加任何其他花里胡哨的模块，但效果比下面要介绍的三个模型都好。",-1),q={href:"https://lileipisces.github.io/",target:"_blank",rel:"noopener noreferrer"},z={href:"http://yongfeng.me/",target:"_blank",rel:"noopener noreferrer"},Y={href:"https://www.comp.hkbu.edu.hk/~lichen/",target:"_blank",rel:"noopener noreferrer"},V={href:"https://arxiv.org/abs/2202.07371",target:"_blank",rel:"noopener noreferrer"},Z={href:"https://github.com/lileipisces/PEPLER",target:"_blank",rel:"noopener noreferrer"},j=r("h3",{id:"peter-transformer",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#peter-transformer","aria-hidden":"true"},"#"),e(" PETER (Transformer)")],-1),K=r("p",null,"本人的另一个工作，采用的是普通的Transformer，同样是用ID来生成推荐解释。由于ID跟文本里的单词比起来过于稀疏，放到一起做attention会有问题（生成的句子高度重复），我们设计了一个额外的任务来连接ID和单词，赋予ID以语言学含义。除了生成解释外，该模型还可以做评分预测（即推荐）。",-1),F={href:"https://lileipisces.github.io/",target:"_blank",rel:"noopener noreferrer"},O={href:"http://yongfeng.me/",target:"_blank",rel:"noopener noreferrer"},W={href:"https://www.comp.hkbu.edu.hk/~lichen/",target:"_blank",rel:"noopener noreferrer"},H={href:"https://dx.doi.org/10.18653/v1/2021.acl-long.383",target:"_blank",rel:"noopener noreferrer"},J={href:"https://github.com/lileipisces/PETER",target:"_blank",rel:"noopener noreferrer"},Q=r("h3",{id:"nrt-gru",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#nrt-gru","aria-hidden":"true"},"#"),e(" NRT (GRU)")],-1),X={href:"http://lipiji.com/",target:"_blank",rel:"noopener noreferrer"},$={href:"http://lipiji.com/",target:"_blank",rel:"noopener noreferrer"},ee={href:"https://dl.acm.org/doi/10.1145/3077136.3080822",target:"_blank",rel:"noopener noreferrer"},re={href:"https://github.com/lipiji/NRT-theano",target:"_blank",rel:"noopener noreferrer"},ne={href:"https://github.com/lileipisces/NRT",target:"_blank",rel:"noopener noreferrer"},te=r("h3",{id:"att2seq-lstm",tabindex:"-1"},[r("a",{class:"header-anchor",href:"#att2seq-lstm","aria-hidden":"true"},"#"),e(" Att2Seq (LSTM)")],-1),oe={href:"http://dong.li/",target:"_blank",rel:"noopener noreferrer"},ae={href:"http://dong.li/",target:"_blank",rel:"noopener noreferrer"},ie={href:"https://aclanthology.org/E17-1059/",target:"_blank",rel:"noopener noreferrer"},se={href:"https://goo.gl/iWzB8P",target:"_blank",rel:"noopener noreferrer"},le={href:"https://github.com/lileipisces/Att2Seq",target:"_blank",rel:"noopener noreferrer"};function he(pe,ce){const n=l("ExternalLinkIcon");return a(),i("div",null,[r("p",null,[r("em",null,[e("Author: "),r("a",p,[e("Lei LI"),t(n)])])]),c,r("p",null,[e("该生态（"),r("a",_,[e("链接"),t(n)]),e("）包括：典型自然语言生成模型的PyTorch实现（预训练模型GPT-2、Transformer、GRU和LSTM），评估指标，公开数据集，以及创建这些数据集的代码。应用场景以推荐系统解释生成（recommendation explanation generation）为例，但不局限于此，可扩展至其他相似应用，如用户评论生成（review generation）、用户评论摘要（review summarization）、提示生成（tip generation）、对话系统（dialogue systems）等。")]),d,r("p",null,[e("对于身在科研一线的朋友们来说，算法和模型的实现/复现有时候比idea还重要。往往一个参数设置的差异，就会导致极不理想的实验结果。就拿PyTorch官方给的Transformer教程来说，里头把gradient clipping设为0.25，极大地限制了模型的梯度更新，进一步限制了模型的学习能力，导致最后生成的文本全是逗号（最高频词）。本人花了大概两三个星期才整明白问题出在哪里（"),r("a",f,[e("观光链接"),t(n)]),e("）。这样的开源项目，无疑会给科研人员造成困扰，同时还会耗费很多时间。另外，有的论文即使开源了代码，但由于实现的时间较早，用的都是上古时代的深度学习框架（如Theano和Torch），跟当前热门的深度学习框架（如PyTorch和TensorFlow）不兼容，需要一定的学习成本。同时，即使是用同一个框架实现的，每个人写代码的风格也千差万别。考虑到这些问题，本人决定把自己实现/复现的自然语言生成模型（可以跑出不错效果）“打包”开源出来，以促进相关领域的发展，同时推广我们自己的工作。")]),g,r("p",null,[e("很多工作将生成的用户评论直接当成推荐解释，我们认为这样是不合理的，因为不是评论里所有的句子都具备解释作用（比如“我昨天去了海底捞”就难以作为解释）。因此，我们的想法是从评论里抽出一些高质量的句子，这些句子包含用户对产品的某方面的评价（比如“这家日料的"),u,e("很"),m,e("”）。那如何得到这些句子呢？我们采用罗格斯大学张永锋老师在他PhD阶段开发的情感分析工具"),r("a",b,[e("Sentires"),t(n)]),e("。这个工具可以从评论里抽出（feature，opinion，sentiment）三元组，比如日料那个句子可以得到（寿司，好吃，+1）。这个工具对于信息检索领域意义重大，因为很多工作都是基于它的结果做的。本人有个朋友就拿它来帮助构建知识图谱。")]),k,r("ul",null,[r("li",null,[r("p",null,[r("a",L,[e("Lei Li"),t(n)]),e(", "),r("a",P,[e("Yongfeng Zhang"),t(n)]),e(", "),r("a",T,[e("Li Chen"),t(n)]),e(". Generate Neural Template Explanations for Recommendation. CIKM'20. ["),r("a",R,[e("Paper"),t(n)]),e("]["),r("a",I,[e("Wrapper"),t(n)]),e("]["),r("a",y,[e("Datasets"),t(n)]),e("]")])]),r("li",null,[r("p",null,[r("a",x,[e("Zhang, Yongfeng"),t(n)]),e(", et al. Do users rate or review? boost phrase-level sentiment labeling with review-level sentiment classification. SIGIR'14. ["),r("a",w,[e("Paper"),t(n)]),e("]["),r("a",C,[e("Toolkit"),t(n)]),e("]")])])]),D,E,r("ul",null,[r("li",null,[r("a",S,[e("Lei Li"),t(n)]),e(", "),r("a",v,[e("Yongfeng Zhang"),t(n)]),e(", "),r("a",G,[e("Li Chen"),t(n)]),e(". Generate Neural Template Explanations for Recommendation. CIKM'20. ["),r("a",N,[e("Paper"),t(n)]),e("]")])]),M,A,U,B,r("ul",null,[r("li",null,[r("a",q,[e("Lei Li"),t(n)]),e(", "),r("a",z,[e("Yongfeng Zhang"),t(n)]),e(", "),r("a",Y,[e("Li Chen"),t(n)]),e(". Personalized Prompt Learning for Explainable Recommendation. ACM Transactions on Information Systems (TOIS), 2023. ["),r("a",V,[e("Paper"),t(n)]),e("]["),r("a",Z,[e("Code"),t(n)]),e("]")])]),j,K,r("ul",null,[r("li",null,[r("a",F,[e("Lei Li"),t(n)]),e(", "),r("a",O,[e("Yongfeng Zhang"),t(n)]),e(", "),r("a",W,[e("Li Chen"),t(n)]),e(". Personalized Transformer for Explainable Recommendation. ACL'21. ["),r("a",H,[e("Paper"),t(n)]),e("]["),r("a",J,[e("Code"),t(n)]),e("]")])]),Q,r("p",null,[e("本人复现的南京航空航天大学"),r("a",X,[e("李丕绩"),t(n)]),e("教授的一个工作。这个工作在推荐系统领域很火，有230+引用。本人刚开始读PhD时读到这篇论文简直醍醐灌顶：模型简洁优雅，文中对推荐系统和自然语言生成两个任务都有非常独到的见解。自然语言生成部分采用的是编码器解码器结构，先用MLP将ID转化成一个向量，再用GRU解码成一段文本。推荐部分采用MLP预测一个评分。最后多个任务（还有一个评论预测被本人去掉了）放到一个多任务学习框架上一起优化。")]),r("ul",null,[r("li",null,[r("a",$,[e("Li, Piji"),t(n)]),e(", et al. Neural Rating Regression with Abstractive Tips Generation for Recommendation. SIGIR'17. ["),r("a",ee,[e("Paper"),t(n)]),e("]["),r("a",re,[e("Code-theano"),t(n)]),e("]["),r("a",ne,[e("Code-pytorch"),t(n)]),e("]")])]),te,r("p",null,[e("本人复现的微软亚洲研究院"),r("a",oe,[e("董力"),t(n)]),e("博士早期的一个工作。这个工作现在在推荐系统领域也很火，有140+引用，无论是做评论生成还是解释生成都会拿它来做baseline。模型也是类似的编码器解码器结构，用MLP将ID转化成一个向量，再用一个两层的LSTM解码成一段文本。")]),r("ul",null,[r("li",null,[r("a",ae,[e("Dong, Li"),t(n)]),e(", et al. Learning to Generate Product Reviews from Attributes. EACL'17. ["),r("a",ie,[e("Paper"),t(n)]),e("]["),r("a",se,[e("Code-torch"),t(n)]),e("]["),r("a",le,[e("Code-pytorch"),t(n)]),e("]")])])])}const de=o(h,[["render",he],["__file","NLG4RS.html.vue"]]);export{de as default};
